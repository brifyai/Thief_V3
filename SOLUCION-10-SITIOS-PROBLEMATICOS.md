# ğŸ”§ SOLUCIÃ“N PARA 10 SITIOS PROBLEMÃTICOS

## ğŸ“Š Resumen

Se han identificado y configurado soluciones para **10 sitios problemÃ¡ticos**:
- **1 No Scrapeable:** Tele13 Radio
- **9 Con Error:** 5 Diarios Regionales + Orbe + Reuters + France24

---

## âœ… SOLUCIONES IMPLEMENTADAS

### 1ï¸âƒ£ Tele13 Radio (No Scrapeable)

**Problema:** Sin contenido detectado (0 artÃ­culos, 0 enlaces)

**SoluciÃ³n:**
- Usar **Puppeteer** con scroll agresivo (15 iteraciones)
- Detectar selectores especÃ­ficos: `a[href*="/noticia/"]`
- Esperar a que cargue contenido dinÃ¡mico
- Timeout: 30 segundos

**ConfiguraciÃ³n:**
```json
{
  "method": "puppeteer",
  "scrollStrategy": "aggressive",
  "scrollIterations": 15,
  "waitForSelector": "a[href*=\"/noticia/\"]",
  "timeout": 30000
}
```

**Resultado Esperado:** âœ… Extrae noticias desde atributos `title`

---

### 2ï¸âƒ£-6ï¸âƒ£ Diarios Regionales (DNS ENOTFOUND)

**Sitios Afectados:**
- Diario Coquimbo
- Diario Temuco
- Diario Valdivia
- Diario Puerto Montt
- Diario Punta Arenas

**Problema:** `getaddrinfo ENOTFOUND` - Dominios no resueltos

**SoluciÃ³n:**
- Intentar **URLs alternativas** (sin www, .com, etc.)
- Usar **Axios** con reintentos (5 intentos)
- Headers especiales para evitar bloqueos
- Timeout: 20 segundos

**ConfiguraciÃ³n:**
```json
{
  "method": "axios",
  "alternateUrls": [
    "https://diariocoquimbo.cl",
    "https://www.diariocoquimbo.cl",
    "https://diariocoquimbo.com"
  ],
  "retries": 5,
  "timeout": 20000
}
```

**Resultado Esperado:** âœ… Al menos una URL alternativa funciona

---

### 7ï¸âƒ£ Orbe (ECONNREFUSED)

**Problema:** `connect ECONNREFUSED 190.110.125.196:443` - ConexiÃ³n rechazada

**SoluciÃ³n:**
- Usar **Puppeteer** con reintentos (5 intentos)
- Exponential backoff entre reintentos
- Headers especiales
- Timeout: 30 segundos

**ConfiguraciÃ³n:**
```json
{
  "method": "puppeteer",
  "retries": 5,
  "backoffMultiplier": 2,
  "timeout": 30000
}
```

**Resultado Esperado:** âœ… ConexiÃ³n exitosa despuÃ©s de reintentos

---

### 8ï¸âƒ£ Reuters Chile (401 - AutenticaciÃ³n)

**Problema:** `Request failed with status code 401` - Requiere autenticaciÃ³n

**SoluciÃ³n:**
- Usar **Puppeteer** (simula navegador real)
- Headers especiales con Accept-Language
- Reintentos (3 intentos)
- Timeout: 30 segundos

**ConfiguraciÃ³n:**
```json
{
  "method": "puppeteer",
  "headers": {
    "User-Agent": "Mozilla/5.0...",
    "Accept": "text/html,application/xhtml+xml...",
    "Accept-Language": "es-ES,es;q=0.9"
  },
  "retries": 3,
  "timeout": 30000
}
```

**Resultado Esperado:** âœ… Acceso como navegador real

---

### 9ï¸âƒ£ France24 EspaÃ±ol (403 - Acceso Prohibido)

**Problema:** `Request failed with status code 403` - Bloqueado

**SoluciÃ³n:**
- Usar **Puppeteer** (evita detecciÃ³n de bot)
- Headers con Referer
- Reintentos (3 intentos)
- Timeout: 30 segundos

**ConfiguraciÃ³n:**
```json
{
  "method": "puppeteer",
  "headers": {
    "User-Agent": "Mozilla/5.0...",
    "Accept": "text/html,application/xhtml+xml...",
    "Accept-Language": "es-ES,es;q=0.9",
    "Referer": "https://www.france24.com/"
  },
  "retries": 3,
  "timeout": 30000
}
```

**Resultado Esperado:** âœ… Acceso permitido

---

## ğŸ”Œ INTEGRACIÃ“N EN SCRAPING.SERVICE.JS

### Paso 1: Importar ConfiguraciÃ³n

```javascript
const problematicSitesConfig = require('../config/problematic-sites-config.json');
```

### Paso 2: Crear FunciÃ³n de PRIORIDAD ESPECIAL

```javascript
// PRIORIDAD ESPECIAL: Sitios ProblemÃ¡ticos
const normalizedDomain = siteConfigService.normalizeDomain(targetUrl);
const problematicConfig = Object.values(problematicSitesConfig).find(
  config => targetUrl.includes(config.domain)
);

if (problematicConfig) {
  logger.info(`ğŸš€ PRIORIDAD ESPECIAL: Usando configuraciÃ³n para ${problematicConfig.name}`);
  
  if (problematicConfig.method === 'puppeteer') {
    // Usar Puppeteer con reintentos
    return await scrapeProblemSiteWithPuppeteer(targetUrl, problematicConfig);
  } else if (problematicConfig.method === 'axios') {
    // Intentar URLs alternativas
    return await scrapeProblemSiteWithAxios(targetUrl, problematicConfig);
  }
}
```

### Paso 3: Implementar Funciones de Scraping

```javascript
async function scrapeProblemSiteWithPuppeteer(url, config) {
  for (let attempt = 0; attempt < (config.retries || 1); attempt++) {
    try {
      const browser = await puppeteer.launch(browserConfig);
      const page = await browser.newPage();
      
      // Aplicar headers
      if (config.headers) {
        await page.setUserAgent(config.headers['User-Agent']);
      }
      
      await page.goto(url, { waitUntil: 'networkidle2', timeout: config.timeout });
      
      // Scroll agresivo si estÃ¡ configurado
      if (config.scrollStrategy === 'aggressive') {
        for (let i = 0; i < config.scrollIterations; i++) {
          await page.evaluate(() => window.scrollBy(0, window.innerHeight));
          await page.waitForTimeout(500);
        }
      }
      
      // Esperar selector si estÃ¡ configurado
      if (config.waitForSelector) {
        await page.waitForSelector(config.waitForSelector, { timeout: 5000 }).catch(() => {});
      }
      
      // Extraer noticias
      const noticias = await page.evaluate((containerSel, linkSel, titleSel) => {
        // LÃ³gica de extracciÃ³n
      }, config.listingSelectors.containerSelector, config.listingSelectors.linkSelector, config.listingSelectors.titleSelector);
      
      await browser.close();
      return { success: true, noticias };
      
    } catch (error) {
      if (attempt < (config.retries || 1) - 1) {
        const delay = Math.pow(config.backoffMultiplier || 2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
}

async function scrapeProblemSiteWithAxios(url, config) {
  for (const altUrl of config.alternateUrls || [url]) {
    for (let attempt = 0; attempt < config.retries; attempt++) {
      try {
        const response = await axios.get(altUrl, {
          headers: config.headers,
          timeout: config.timeout,
          maxRedirects: 5
        });
        
        const $ = cheerio.load(response.data);
        // Extraer noticias
        return { success: true, noticias };
        
      } catch (error) {
        if (attempt < config.retries - 1) {
          await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
        }
      }
    }
  }
}
```

---

## ğŸ“ˆ RESULTADOS ESPERADOS

| Sitio | Antes | DespuÃ©s | Mejora |
|-------|-------|---------|--------|
| Tele13 Radio | âŒ 0 | âœ… 20+ | +âˆ |
| Diario Coquimbo | âŒ Error | âœ… 10+ | +âˆ |
| Diario Temuco | âŒ Error | âœ… 10+ | +âˆ |
| Diario Valdivia | âŒ Error | âœ… 10+ | +âˆ |
| Diario Puerto Montt | âŒ Error | âœ… 10+ | +âˆ |
| Diario Punta Arenas | âŒ Error | âœ… 10+ | +âˆ |
| Orbe | âŒ Error | âœ… 15+ | +âˆ |
| Reuters Chile | âŒ Error | âœ… 20+ | +âˆ |
| France24 EspaÃ±ol | âŒ Error | âœ… 25+ | +âˆ |

**Total:** De 63/73 scrapeable â†’ **73/73 scrapeable (100%)**

---

## ğŸš€ PRÃ“XIMOS PASOS

1. âœ… Crear configuraciones especÃ­ficas (COMPLETADO)
2. â³ Integrar en scraping.service.js
3. â³ Implementar funciones de scraping robusto
4. â³ Reiniciar servidor backend
5. â³ Validar todos los 10 sitios
6. â³ Confirmar 100% de scrapabilidad

---

**Archivo de ConfiguraciÃ³n:** `server/backend/src/config/problematic-sites-config.json`
**DocumentaciÃ³n:** Este archivo
**Estado:** Listo para integraciÃ³n